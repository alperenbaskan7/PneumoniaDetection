# -*- coding: utf-8 -*-
"""PneumoniaDetectionwithCNN-confusion-matrix.ipynb  adlı not defterinin kopyası

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CXt_vjlIjw5AyqgZpD8MnFT9E4Yu99Tp
"""

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.layers import *
from keras.preprocessing import image
from keras.models import Sequential
from keras.optimizers import SGD

# convolution, dropout and max pool. layers added
opt = SGD(learning_rate = 0.001)
model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=(256, 256, 3),padding = 'same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3),padding = 'same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, (3, 3),padding = 'same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(256, (3, 3),padding = 'same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

from keras import regularizers

model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(512,kernel_regularizer=regularizers.l2(1e-4)))
model.add(Activation('relu'))
model.add(Dropout(0.5))
# the final classification is done via fully connected layers
model.add(Dense(3))
model.add(Activation('softmax'))
model.summary()
# categorical crossentropy is used since there are 3 classes
model.compile(loss = 'categorical_crossentropy',
              optimizer = 'Adam',
              metrics = ['accuracy'])

# image preprocessing and augmentation
train_datagen = image.ImageDataGenerator(
      rescale=1./256,
      shear_range=0.1, #0.2
      zoom_range=0.1, #0.2
      horizontal_flip=True,
      )
test_dataset = image.ImageDataGenerator(rescale=1./256)

#Take the path to a directory
train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/dataset-xgboost/training',
    target_size = (256,256),
    color_mode = 'rgb',
    batch_size = 32, 
    class_mode= 'categorical'
)

train_generator.class_indices

# take validation path to a directory
validation_generator = test_dataset.flow_from_directory(
    '/content/drive/MyDrive/dataset-xgboost/validation',
    target_size = (256,256),
    batch_size = 32, 
    class_mode = 'categorical',
    shuffle = False
)


STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size
STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size

#Configure the model for training
history = model.fit(train_generator,
                    steps_per_epoch=40, 
                    validation_data=validation_generator,
                    validation_steps=2, 
                    epochs=100,
         )

print(history.history.keys())
# plot model accuracy
plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Training Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

# save the model
model.save("network.h5")

from sklearn.metrics import classification_report, confusion_matrix
Y_pred = model.predict(validation_generator, 464 // 32+1)
y_pred = np.argmax(Y_pred, axis=1)
print('Confusion Matrix')
print(confusion_matrix(validation_generator.classes, y_pred))
print('Classification Report')
target_names = ['covid', 'normal', 'pneumonia']
print(classification_report(validation_generator.classes, y_pred, target_names=target_names))