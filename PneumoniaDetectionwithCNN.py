# -*- coding: utf-8 -*-
"""PneumoniaDetectionwithCNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Waq90OabmimPgdscZXjXZyHNTiQ8nukv
"""

import numpy as np
import matplotlib.pyplot as plt
import keras
from keras.layers import *
from keras.preprocessing import image
from keras.models import Sequential
from keras.optimizers import SGD

opt = SGD(learning_rate = 0.001)
model = Sequential()
model.add(Conv2D(32, (3, 3), input_shape=(256, 256, 3),padding = 'same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(64, (3, 3),padding = 'same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(128, (3, 3),padding = 'same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Conv2D(256, (3, 3),padding = 'same'))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

from keras import regularizers

model.add(Flatten())
model.add(Dropout(0.5))
model.add(Dense(512,kernel_regularizer=regularizers.l2(1e-4)))
model.add(Activation('relu'))
model.add(Dropout(0.5))
model.add(Dense(3))
model.add(Activation('softmax'))
model.summary()
model.compile(loss = 'categorical_crossentropy',
              optimizer = 'Adam',
              metrics = ['accuracy'])

train_datagen = image.ImageDataGenerator(
      rescale=1./256,
      shear_range=0.1, #0.2
      zoom_range=0.1, #0.2
      horizontal_flip=True,
      )
test_dataset = image.ImageDataGenerator(rescale=1./256)

train_generator = train_datagen.flow_from_directory(
    '/content/drive/MyDrive/dataset/training/',
    target_size = (256,256),
    color_mode = 'rgb',
    batch_size = 32, 
    class_mode= 'categorical'
)

train_generator.class_indices

validation_generator = test_dataset.flow_from_directory(
    '/content/drive/MyDrive/dataset/validation/',
    target_size = (256,256),
    batch_size = 32, 
    class_mode = 'categorical'
)


STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size
STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size
#STEP_SIZE_TEST=test_generator.n//test_generator.batch_size

history = model.fit(train_generator,
                    steps_per_epoch=89, #STEP_SIZE_TRAIN,
                    validation_data=validation_generator,
                    validation_steps=3, #STEP_SIZE_VALID,
                    epochs=100, #60
         )

print(history.history.keys())

plt.plot(history.history['accuracy'], label='accuracy')
plt.plot(history.history['val_accuracy'], label = 'val_accuracy')
plt.xlabel('Epoch')
plt.ylabel('Training Accuracy')
plt.ylim([0.5, 1])
plt.legend(loc='lower right')

#test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)

#from keras.models import load_model
model.save("network.h5")
#loaded_model = load_model("network.h5")
#loss, accuracy = loaded_model.evaluate(test_data, test_targets)