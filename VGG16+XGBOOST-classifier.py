# -*- coding: utf-8 -*-
"""FINAL-VGG16+XGBoost Pneumonia Detector v2.0

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18i4Dam2ucpoJTVKZdMw82JiLydzQlx5J
"""

import numpy as np 
import matplotlib.pyplot as plt
import glob
import cv2

from keras.models import Model, Sequential
from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D
from keras.layers.normalization import BatchNormalization
import os
import seaborn as sns
from keras.applications.vgg16 import VGG16

print(os.listdir("/content/drive/MyDrive/dataset-xgboost"))

SIZE = 256
train_images = []
train_labels = []

for directory_path in glob.glob("/content/drive/MyDrive/dataset-xgboost/training/*"):
    label = directory_path.split("\\")[-1]
    label= label.replace("/content/drive/MyDrive/dataset-xgboost/training/","")
    print(label)
    for img_path in glob.glob(os.path.join(directory_path, "*.png")):
        print(img_path)
        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       
        img = cv2.resize(img, (SIZE, SIZE))
        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
        train_images.append(img)
        train_labels.append(label)

train_images = np.array(train_images)
train_labels = np.array(train_labels)

test_images = []
test_labels = []
for directory_path in glob.glob("/content/drive/MyDrive/dataset-xgboost/validation/*"):
    label = directory_path.split("\\")[-1]
    label= label.replace("/content/drive/MyDrive/dataset-xgboost/validation/","")
    print(label)
    for img_path in glob.glob(os.path.join(directory_path, "*.png")):
        print(img_path)
        img = cv2.imread(img_path, cv2.IMREAD_COLOR)       
        img = cv2.resize(img, (SIZE, SIZE))
        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)
        test_images.append(img)
        test_labels.append(label)

test_images = np.array(test_images)
test_labels = np.array(test_labels)

from sklearn import preprocessing
le = preprocessing.LabelEncoder()
le.fit(test_labels)
test_labels_encoded = le.transform(test_labels)
le.fit(train_labels)
train_labels_encoded = le.transform(train_labels)

x_train, y_train, x_test, y_test = train_images, train_labels_encoded, test_images, test_labels_encoded

x_train, x_test = x_train / 255.0, x_test / 255.0

VGG_model = VGG16(weights='imagenet', include_top=False, input_shape=(SIZE, SIZE, 3))

for layer in VGG_model.layers:
	layer.trainable = False
    
VGG_model.summary()

feature_extractor=VGG_model.predict(x_train)

features = feature_extractor.reshape(feature_extractor.shape[0], -1)

X_for_training = features

import xgboost as xgb
model = xgb.XGBClassifier(n_estimators=110)
model.fit(X_for_training, y_train)

X_test_feature = VGG_model.predict(x_test)
X_test_features = X_test_feature.reshape(X_test_feature.shape[0], -1)

prediction = model.predict(X_test_features)
prediction = le.inverse_transform(prediction)

from sklearn import metrics
print ("Accuracy = ", metrics.accuracy_score(test_labels, prediction))
#print(test_labels)
#print(prediction)

from sklearn.metrics import confusion_matrix

cm = confusion_matrix(test_labels, prediction)
#print(cm)
sns.heatmap(cm, annot=True)

#Check results on a few select images
n=np.random.randint(0, x_test.shape[0])
img = x_test[n]
plt.imshow(img)
input_img = np.expand_dims(img, axis=0) #Expand dims so the input is (num images, x, y, c)
input_img_feature=VGG_model.predict(input_img)
input_img_features=input_img_feature.reshape(input_img_feature.shape[0], -1)
prediction = model.predict(input_img_features)[0] 
prediction = le.inverse_transform([prediction])  #Reverse the label encoder to original name
print("The prediction for this image is: ", prediction)
print("The actual label for this image is: ", test_labels[n])

import pickle
pickle.dump(model, open("vgg16+xgb.dat", "wb"))